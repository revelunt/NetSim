
\documentclass[man, 12pt, a4paper]{apa6}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{times}

%% You can pass in your own texcount params, e.g. -chinese to turn on Chinese mode, or -char to do a character count instead (which does NOT include spaces!)
%%% http://app.uio.no/ifi/texcount/documentation.html
\newcommand{\detailtexcount}{%
  \immediate\write18{texcount -merge -sum -incbib -dir \jobname.tex > \jobname.wcdetail }%
  \verbatiminput{\jobname.wcdetail}%
}

\newcommand{\quickwordcount}{%
  \immediate\write18{texcount -1 -sum -merge \jobname.tex > \jobname-words.sum }%
  \input{\jobname-words.sum} words%
}

\newcommand{\quickcharcount}{%
  \immediate\write18{texcount -1 -sum -merge -char \jobname.tex > \jobname-chars.sum }%
  \input{\jobname-chars.sum} characters (not including spaces)%
}


% Biblatex
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber,uniquename=false]{biblatex}
\usepackage[colorlinks=true]{hyperref}

\addbibresource{abm_misinformation_lit.bib}
\DeclareLanguageMapping{american}{american-apa}
 
\title{If you see something, say something (to others): A spread of misinformation and socially-contingent corrections within social networks}
\shorttitle{The socially-contingent corrections}

\author{Hyunjin Song}

\affiliation{Department of Communication, University of Vienna, Austria}


\abstract{As the citizens' news consumption is increasingly driven by online sources, the propagation of misinformation and so-called \enquote{fake news} on those platforms become an increasing concern for the public and policy makers. Yet what we know about the spread of misinformation and fake news is largely based on anecdotal evidence despite increasing academic interest and research effort on this topic. Our goal in this contribution is to offer a more systematic assessment of underlying mechanisms of misinformation spreading and its correction, combining a macro social contextual factor and individuals' cognitive basis of adopting misinformation into a more integrated, dynamic system model perspective. We first review existing evidence concerning individuals' cognitive basis of adopting such misinformation, focusing motivated reasoning and accuracy motivations, and social context of which exposure to misinformation and its corrections are received. Next, adopting a well-known class of an epidemic model of virus infection and recovery, we combine this micro and macro dynamics into comprehensive, integrated model of misinformation diffusion on social networks, focusing on the distinction between simple vs. complex contagion. Relying on Agent-based simulations, we further explore various boundary conditions of such dynamics, aiming to uncover how and when such misinformation propagates into the public, as well as what factors facilitate or hinder such diffusion process.}

\authornote{Hyunjin (Jin) Song is currently an assistant professor ("Universit√§tsassistent, post-doc") in the Department of Communication at the University of Vienna, and also a member of the Vienna Computational Communication Science Lab.}

\note{Word count: \quickwordcount \\
      \textbf{Draft in progress. Please do not cite without permission.} Please direct any questions and inquiries to \href{mailto:hyunjin.song@univie.ac.at}{hyunjin.song@univie.ac.at}}

\begin{document}
\maketitle
Citizens across the worlds are experiencing major changes in their news environment with the development of digital media. One of the most dramatic changes in the news environment involves the role social networking sites (SNS) such as Facebook and Twitter play as a primary source of news outlets. Not only citizens' news consumption is increasingly driven by online sources \parencite{shearer2017news}, but it also appears that citizens themselves are actively participating in news dissemination by sharing news contents in social media \parencite[e.g.,][]{weeks2013dissemination}. 

Along with these trends, the propagation of rumors, misinformation, and so-called \enquote{Fake news} on those platforms become an increasing concern for the public and policy makers \parencite{allcott2017social}. There are abundant, yet still fragmentary, evidence of viral spreads of unsubstantiated, often factually dubious (mis)information and "fake news" that potentially affecting millions of citizens across the globe, as evidenced in recent 2016 U.S. presidential election \parencite{guess2018selective, giglietto2016fakes, allcott2017social} and in Brexit votes \parencite{nyt_2017}. While neither the wide circulation of factually dubious information nor individuals' ressentiments towards corrective messages that are attitudinally incongruent to their priors are not new, a growing trend of digitally disseminated rumors and misinformations -- often termed as a \enquote{Fake news} -- is increasingly recognized as a serious threat to liberal democratic societies \parencite{allcott2017social,LEWANDOWSKY_JARMC2017}. Despite growing interest and continued research effort to better understand the nature and exact mechanisms of such a propagation, what we know about the spread of misinformation and fake news on online social networks is yet largely based on limited evidence due to its complex nature of the problem.

Relatedly, there has been an growing interest among scholars on how people process and maintain factually false (or at least factually dubious) information from the perspectives of an individual's cognitive and affective mechanisms \parencite{LEWANDOWSKY_JARMC2017, garrett2016driving, weeks2015emotions}. These studies have generated a valuable insights of how individuals maintain false beliefs, and how corrections to such false beliefs is received and processed under various scenarios \parencite{LEWANDOWSKY_JARMC2017, thorson_2016}. A mounting evidence -- largely based on \citeauthor{kunda1990}'s (\citeyear{kunda1990}) or on \citeauthor{taber2006}'s (\citeyear{taber2006}) motivated reasoning framework -- suggests that fact-checking messages on false information (sometimes denoted as \enquote{corrective} or \enquote{debunking} messages in the literature) have only limited effects due to inherent tendency of humans to directionally process (politically) relevant information \parencite{thorson_2016, nyhan2010corrections, taber2006}. Yet at the same time, studies also find that, under certain situations, citizens \emph{indeed} can adhere factual information based on correction messages in spite of partisan bias \parencite[e.g.,][]{Wood2018, Garrett_Weeks_2013, weeks2015emotions}. 

Against this backdrop, our goal in this contribution is to offer a more systematic assessment of underlying mechanisms of misinformation spreading and its correction, focusing on one's \emph{social} contexts in which such exposure to (mis)information and corrective messages are received and processed. We argue while \emph{exposure} to (mis)information is likely to follow a simple contagion process, \emph{changes} in one's beliefs regarding such (mis)information -- which ultimately \emph{the} goal of corrective messages -- is likely to be, in \citeauthor{centola2007complex}'s (\citeyear{centola2007complex}) term, a \enquote{complex contagion} where such changes require multiple sources of affirmation and reinforcement compared to simple contagion process. As a result, the effects of fact-checking and corrective messages are likely to be highly \emph{socially} contingent, and we argue that vast of prior studies have not considered this possibility to date \parencite[for a notable exception, see][]{margolin2017}.    

In what follows, we first review existing evidence regarding political misperceptions and the effect of fact-checking messages. We advance our dynamic system model perspective by combining an individual-level cognitive and affective basis of adopting such misinformation with a social context of which an exposure to misinformation and corrections are received. Based on a well-known class of an epidemic model of virus infection and recovery, we propose an integrated model of misinformation diffusion and socially-contingent corrections on social networks, with a special focus on the differences between simple contagion of misinformation and complex contagion of corrections. Relying on Agent-based simulations, we further explore various boundary conditions of such dynamics, aiming to uncover how and when such misinformation propagates into the public, as well as what factors facilitate or hinder such diffusion process.

\section{Theoretical framework}

Following \citeauthor{allcott2017social}'s (\citeyear{allcott2017social}) definition, we define misinformation and fake news as \enquote{distorted signals uncorrelated with the truth} (p. 212). Based on this definition, we ....




\printbibliography
\end{document}
