% declare documents and packages
\documentclass[man, 12pt, a4paper]{apa6}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{times}
\usepackage{endnotes}
% this command put all footnotes to endnote at the end of the paper
\let\footnote\endnote

% for word counts
\newcommand{\detailtexcount}{%
  \immediate\write18{texcount -merge -sum -incbib -dir \jobname.tex > \jobname.wcdetail }%
  \verbatiminput{\jobname.wcdetail}%
}
\newcommand{\quickwordcount}{%
  \immediate\write18{texcount -1 -sum -merge \jobname.tex > \jobname-words.sum }%
  \input{\jobname-words.sum} words%
}
\newcommand{\quickcharcount}{%
  \immediate\write18{texcount -1 -sum -merge -char \jobname.tex > \jobname-chars.sum }%
  \input{\jobname-chars.sum} characters (not including spaces)%
}

% Biblatex
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber,uniquename=false]{biblatex}
\usepackage[colorlinks=true]{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\addbibresource{abm_misinformation_lit.bib}
\DeclareLanguageMapping{american}{american-apa}
 
\title{If you see something, say something (to others): A spread of misinformation and socially-contingent corrections within social networks}
\shorttitle{Socially-contingent corrections}

\author{Hyunjin Song}

\affiliation{Department of Communication, University of Vienna, Austria}


\abstract{As the citizens' news consumption is increasingly driven by online sources, the propagation of misinformation and so-called \enquote{fake news} on those platforms become an increasing concern for the public and policy makers. Our goal in this contribution is to offer a more systematic assessment of underlying mechanisms of misinformation spreading and its correction, combining a macro social contextual factor and individuals' cognitive basis of adopting misinformation into a more integrated, dynamic system model perspective. We first review existing evidence concerning individuals' cognitive basis of adopting such misinformation, and social context of which exposure to misinformation and its corrections are received. Next, adopting a well-known class of an epidemic model of virus infection and recovery, we combine this micro and macro dynamics into comprehensive, integrated model of misinformation diffusion on social networks. We do so by focusing on the distinction between simple contagion of misinformation vs. complex contagion of adopting corrective messages. Relying on Agent-based simulations, we further explore various boundary conditions of such dynamics, aiming to uncover how and when such misinformation propagates into the public, as well as what factors facilitate or hinder such diffusion process.}

\authornote{Hyunjin (Jin) Song is currently an assistant professor ("Universit√§tsassistent, post-doc") in the Department of Communication at the University of Vienna, and also a member of the Vienna Computational Communication Science Lab.}

\note{Word count: \quickwordcount \\
	  Draft date: \today \\
      \textbf{Draft in progress. Please do not cite without permission.} \\
      Please direct any questions and inquiries to \href{mailto:hyunjin.song@univie.ac.at}{hyunjin.song@univie.ac.at}}

\begin{document}
\maketitle
	Citizens across the worlds are experiencing major changes in their news environments with the development of digital media. One of the most dramatic changes in the news environment in recent decades involves the role social networking sites (SNS) such as Facebook and Twitter play as a primary source of news outlets. Not only citizens' news consumptions are increasingly driven by such online sources \parencite{shearer2017news}, but it also appears that citizens themselves are actively participating in news dissemination on those platforms by sharing news contents with their peers \parencite[e.g.,][]{weeks2013dissemination, lee2017people}. 

	An effective deliberation among public is regarded as a keystone of thriving democracies, and modern political systems squarely depend  on  informed  decisions of citizens in that regard \parencite{carpini1996, stromback2005search}. Yet, a propagation of rumors, misinformation, and so-called \enquote{Fake news} on those platforms becomes an increasing concern for the public and policy makers alike \parencite{allcott2017social}. There are abundant, yet still fragmentary, evidence of viral spreads of unsubstantiated, often factually dubious (mis)information that potentially affecting millions of citizens across the globe -- as evidenced in recent 2016 U.S. presidential election \parencite{guess2018selective, giglietto2016fakes, allcott2017social} and in Brexit votes \parencite{nyt_2017}. While a wide circulation of factually dubious information is not entirely new to politics, a growing trend of digitally disseminated rumors and misinformations -- often termed as a \enquote{Fake news} phenomenon -- is increasingly recognized as a serious threat to liberal democratic societies \parencite{allcott2017social, LEWANDOWSKY_JARMC2017}. Either based on unsubstantiated rumors or based on factually wrong beliefs, many of the misinformed behave differently than those who are accurately informed \parencite{kuklinski2000misinformation,Garrett_Weeks_2013}. They often disagree about basic facts about many political and public issues \parencite[e.g.,][]{nisbet2015partisan}, and continue to believe and rely on such false information when evaluating political matters \parencite{nyhan2010corrections,thorson_2016}. 

	Along with these trends, there has been an growing interest among scholars on how people process and maintain factually false (or at least factually dubious) information from the perspectives of an individual's cognitive and affective mechanisms \parencite{LEWANDOWSKY_JARMC2017, Lewandowsky_2012PSPI, kuklinski2000misinformation, garrett2016driving, weeks2015emotions}. These studies have generated a valuable insights of how individuals maintain false beliefs, and how corrections to such false beliefs are received and processed under various scenarios \parencite{LEWANDOWSKY_JARMC2017, thorson_2016}. However, despite growing interest and continued research effort to better understand the nature and its exact mechanism, what we know about the spread of misinformation and fake news on online social networks is largely based on limited evidence due to its complex nature of the problem.

	Against this backdrop, our goal in this contribution is to offer a more systematic assessment of underlying mechanisms of misinformation spreading and its correction, focusing on one's \emph{social contexts} in which such (mis)information and corrective messages are received and processed. We argue that while \emph{exposure} to (mis)information is likely to follow a simple contagion process, \emph{changes} in one's beliefs regarding such (mis)information -- which ultimately \emph{the} goal of corrective messages -- is likely to be, in \citeauthor{centola2007complex}'s (\citeyear{centola2007complex}) term, a \enquote{complex contagion} where such changes require multiple sources of affirmation and reinforcement compared to simple contagion process. As a result, the effects of fact-checking and corrective messages are likely to be highly \emph{socially} contingent, yet the vast majority of prior studies have not considered this possibility to date \parencite{margolin2017}.    

	In what follows, we first review existing evidence regarding political misperceptions and the effect of fact-checking (i.e., corrective) messages. We advance our dynamic system perspective by combining an individual-level cognitive and affective basis of adopting such misinformation with a social context of which an exposure to misinformation and corrections are received. Based on a well-known class of an epidemic model of virus infection and recovery, we propose an integrated model of misinformation diffusion and socially-contingent corrections on social networks, with a special focus on the differences between simple contagion of misinformation and complex contagion of corrections. Relying on Agent-based simulations, we further explore boundary conditions of such dynamics, aiming to uncover how and when such misinformation propagates into the public, as well as what factors facilitate or hinder such diffusion process.

\section{A Psychology of Fake News, Misperceptions, and Corrections}

     Following \citeauthor{allcott2017social}'s (\citeyear{allcott2017social}) definition, we define \emph{Fake news} as \enquote{distorted signals uncorrelated with the truth} (p. 212). This encompasses several related concepts, such as misinformation, rumors, and disinformation. Literature on this topic generally maintain loosely defined, but at the same time highly interrelated, definitions of those related terms. For instance, (political) rumors are often defined as \enquote{unsubstantiated claims about candidates and issues that are often false} \parencite[p. 401]{weeks2014electoral}. Similarly, misinformation (or misperceptions) are defined as factual information (or beliefs) \enquote{that are false or contradict the best available evidence in the public domain} \parencite[p. 128]{flynn2017nature}. In relation to this, \emph{dis}information campaigns often denote organized, strategic efforts that trying to sway public opinion using rumors and misinformation \parencite{Garrett2017distraction, Lewandowsky_2012PSPI}. Understood in this way, fake news often exclude unintentional reporting mistakes, parodies and satires, or unverifiable conspiracy theories \parencite{allcott2017social}. While term \emph{fake news} often than not additionally entail specific pseudo-journalistic styles that mimic legitimate news sources to intentionally deceiving audiences \parencite{jana_sophie_fn}, we use term \enquote{fake news} somewhat loosely, denoting any type of misinformation -- information that is not supported by best-available evidence -- that is deliberatively circulated among publics.\footnote{	Often, the term \emph{fake news} is used as derogatory, rhetorical label to attack political opponents. While such use of the term as a \emph{label} is an important conceptual dimension to consider, this aspects of \emph{fake news} is beyond the scope of this manuscript. See \citeauthor{jana_sophie_fn} (\citeyear{jana_sophie_fn}) instead for a detailed conceptualization involving this distinction.}
     
      Literature on misinformation and its persistence often converges to the observation that publics' exposure to and acceptance of misinformation are largely driven by one's motivated consistency needs. That is, people are more often than not likely to be disproportionately drawn by information that conforms to their partisan priors \parencite{guess2018selective, weeks2014electoral}, and also more likely to accept and endorse such messages \parencite{kunda1990,nyhan2010corrections}. A mounting evidence -- largely based on \citeauthor{kunda1990}'s (\citeyear{kunda1990}) or on \citeauthor{taber2006}'s (\citeyear{taber2006}) motivated reasoning framework -- suggests that citizens tend to evaluate attitudinally congruent information as more convincing and valid \emph{regardless of its truth-value}, while inconsistent information is likely to be perceived as weak and therefore likely to be rejected \parencite{taber2006,weeks2015emotions}. Therefore, it is perhaps not surprising to find that most of the prior studies based on motivated reasoning framework document that fact-checking messages (sometimes denoted as \enquote{corrective} or \enquote{debunking} messages in the literature) have only limited effects due to inherent tendency of humans to directionally process (politically) relevant information \parencite{thorson_2016, taber2006,flynn2017nature}. Or worse, often such corrective messages may backfire \parencite[i.e., more likely to increase than lower the endorsement of false beliefs:][]{nyhan2010corrections}.
      
      Another line of studies focusing on an individual-level cognitive processing and memory suggests that while attitudinally-congruent misinformation creates automatic and strong affective responses (therefore more easily remembered and readily available in their memory), corrections rarely produce such responses, and therefore requires more resources to recall and incorporate into relevant judgments \parencite{thorson_2016, Lewandowsky_2012PSPI}. Also, since misinformations tend to form a coherent mental model of an relevant event based on their partisan schema or based on stereotypes \parencite[e.g.,][]{garrett2013undermining}, people tend to fill any gaps caused by corrections (that invalidates some parts of the mental model) with flawed but attitudinally congruent (mis)information available in memory \parencite{Lewandowsky_2012PSPI}, especially when correction messages does not update the initial mental model that justifies misinformation \parencite{Chan_debunking_meta_2017}. Studies also find that this effect is much likely when initial misinformation is more readily accessible due to fluency bias in one's cognitive processing \parencite{lazer2017combating, Lewandowsky_2012PSPI}, when individuals can generate (counter-arguing) reasons in support for initial misperceptions \parencite{garrett2013undermining, Chan_debunking_meta_2017}, and most importantly, \emph{even when they remember such information is factually incorrect} \parencite{Lewandowsky_2012PSPI}. Due to asymmetrical nature in one's cognitive processing fluency, people have to rely on more deliberative process to recall attitudinally inconsistent correction messages (which requires significant  resources), whereas misinformation is more easily processed and automatically activated. Therefore, even in the face of corrections, the effect of misperceptions linger and continue to exert influence on subsequent judgments via spontaneous (i.e., automatic) affective process \parencite[e.g.,][]{thorson_2016}.    
      
      However, other studies also find that, under certain situations, citizens \emph{indeed} can adhere factual information based on correction messages despite of their perpetual partisan bias \parencite[e.g.,][]{Wood2018, Garrett_Weeks_2013, weeks2015emotions}. Notably, \citeauthor{Wood2018}'s (\citeyear{Wood2018}) series of experiments document that    




\printbibliography
\newpage
\begingroup
\parindent 0pt
\parskip 2ex
\def\enotesize{\normalsize}
\theendnotes
\endgroup
\end{document}
